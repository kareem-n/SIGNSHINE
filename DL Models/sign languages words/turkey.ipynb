{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":147400115,"sourceType":"kernelVersion"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-27T02:32:44.734773Z","iopub.execute_input":"2023-10-27T02:32:44.735142Z","iopub.status.idle":"2023-10-27T02:32:45.186706Z","shell.execute_reply.started":"2023-10-27T02:32:44.735111Z","shell.execute_reply":"2023-10-27T02:32:45.185559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\n\n# Create a zip file object\nwith zipfile.ZipFile(\"/kaggle/input/working-on-tur/_output_.zip\", \"r\") as zip_obj:\n    # Extract all the files to a directory\n    zip_obj.extractall(\"/kaggle/working/\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:32:45.188385Z","iopub.execute_input":"2023-10-27T02:32:45.191027Z","iopub.status.idle":"2023-10-27T02:33:57.160496Z","shell.execute_reply.started":"2023-10-27T02:32:45.190988Z","shell.execute_reply":"2023-10-27T02:33:57.159368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nimport numpy as np\nimport pandas as pd\nimport os\nimport shutil\nimport datetime as dt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport glob\nimport cv2\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Bidirectional, LSTM, Dense\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.metrics import multilabel_confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nnp.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:33:57.162632Z","iopub.execute_input":"2023-10-27T02:33:57.162991Z","iopub.status.idle":"2023-10-27T02:34:11.415167Z","shell.execute_reply.started":"2023-10-27T02:33:57.162961Z","shell.execute_reply":"2023-10-27T02:34:11.413807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_words = os.listdir('/kaggle/working/Dataset/frames/Train')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:34:11.418236Z","iopub.execute_input":"2023-10-27T02:34:11.420427Z","iopub.status.idle":"2023-10-27T02:34:11.426560Z","shell.execute_reply.started":"2023-10-27T02:34:11.420367Z","shell.execute_reply":"2023-10-27T02:34:11.424952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = os.listdir('/kaggle/working/Dataset/frames/Train')\nlabel_map = {label:num for num, label in enumerate(words)}\nprint(label_map)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:34:11.430826Z","iopub.execute_input":"2023-10-27T02:34:11.431498Z","iopub.status.idle":"2023-10-27T02:34:12.724668Z","shell.execute_reply.started":"2023-10-27T02:34:11.431463Z","shell.execute_reply":"2023-10-27T02:34:12.723567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(data_path,split,f_avg):\n\n    # Initialize the lists of sequences and labels\n    sequences = []\n    labels = []\n    \n    # Iterate over the words\n    for word in tqdm(words):\n        word_path = os.path.join(data_path, split, word)\n        word_id = os.path.basename(word_path).zfill(4)\n    \n        lh_keypoints_folder = os.path.join(word_path, \"lh_keypoints\")\n        rh_keypoints_folder = os.path.join(word_path, \"rh_keypoints\")\n        pose_keypoints_folder = os.path.join(word_path, \"pose_keypoints\")\n    \n        # Iterate through the sequences (numpy arrays) contained in the lh_keypoints folder\n        for sequence in os.listdir(lh_keypoints_folder):\n            # Load the left hand array\n            res_lh = np.load(os.path.join(lh_keypoints_folder, sequence))\n    \n            # Determine how many frames to select\n            num_frames = min(res_lh.shape[0], f_avg)\n            res_lh = res_lh[:num_frames, :]\n            while num_frames < f_avg:\n                res_lh = np.concatenate((res_lh, np.expand_dims(res_lh[-1, :], axis=0)), axis=0)\n                num_frames += 1\n    \n            # Load the right hand array\n            res_rh = np.load(os.path.join(rh_keypoints_folder, sequence))\n    \n            # Determine how many frames to select\n            num_frames = min(res_rh.shape[0], f_avg)\n            res_rh = res_rh[:num_frames, :]\n            while num_frames < f_avg:\n                res_rh = np.concatenate((res_rh, np.expand_dims(res_rh[-1, :], axis=0)), axis=0)\n                num_frames += 1\n    \n            # Load the pose array\n            res_pose = np.load(os.path.join(pose_keypoints_folder, sequence))\n    \n            # Determine how many frames to select\n            num_frames = min(res_pose.shape[0], f_avg)\n            res_pose = res_pose[:num_frames, :]\n            while num_frames < f_avg:\n                res_pose = np.concatenate((res_pose, np.expand_dims(res_pose[-1, :], axis=0)), axis=0)\n                num_frames += 1\n    \n#             # Append the subsequence to the list of sequences\n            sequences.append(np.concatenate((res_pose,res_lh, res_rh), axis=1))\n            # Append the label to the list of labels\n            labels.append(label_map[word])\n    \n    # Convert the lists of sequences and labels to numpy arrays\n    X = np.array(sequences)\n    y = to_categorical(labels).astype(int)\n    \n    return X, y","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:34:12.726706Z","iopub.execute_input":"2023-10-27T02:34:12.727531Z","iopub.status.idle":"2023-10-27T02:34:13.344279Z","shell.execute_reply.started":"2023-10-27T02:34:12.727489Z","shell.execute_reply":"2023-10-27T02:34:13.343109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lista = []\ntoFrames = '/kaggle/working/Dataset/frames'\nfor fold in os.listdir(toFrames):\n    toTrain = os.path.join(toFrames,fold)\n    for word in os.listdir(toTrain):\n        toWord = os.path.join(toTrain,word)\n        for vid in os.listdir(toWord):\n            toVid = os.path.join(toWord,vid)\n            lista.append(int(len(os.listdir(toVid))))\nmapa = {}\nfor i in lista : \n    mapa[i] = 0\nfor i in lista:\n    mapa[i]+=1\nmedian = []\nfor k,v in mapa.items():\n    if v>=len(words):\n        median.append(k)\navg = round(sum(median)/len(median))\n\navg = np.sort(median)[-1]\navg","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:34:13.346131Z","iopub.execute_input":"2023-10-27T02:34:13.347383Z","iopub.status.idle":"2023-10-27T02:34:13.632871Z","shell.execute_reply.started":"2023-10-27T02:34:13.347338Z","shell.execute_reply":"2023-10-27T02:34:13.631903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train and validation splits\ndata_path = '/kaggle/working/Dataset/npy_arrays'\n\nX_train,y_train=preprocess_data(data_path,'Train/',48)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n# X_train = np.concatenate(X_train,X_val)\n# y_train=np.concatenate(y_train,y_val)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:34:13.635936Z","iopub.execute_input":"2023-10-27T02:34:13.637041Z","iopub.status.idle":"2023-10-27T02:34:29.973269Z","shell.execute_reply.started":"2023-10-27T02:34:13.637004Z","shell.execute_reply":"2023-10-27T02:34:29.971994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test split\nX_test,y_test=preprocess_data(data_path,'Test',48)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:34:29.974775Z","iopub.execute_input":"2023-10-27T02:34:29.975478Z","iopub.status.idle":"2023-10-27T02:34:35.248190Z","shell.execute_reply.started":"2023-10-27T02:34:29.975443Z","shell.execute_reply":"2023-10-27T02:34:35.247095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Define the Bidirectional LSTM model with Attention\n# model = tf.keras.Sequential([\n#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n# #     tf.keras.layers.BatchNormalization(),\n#     tf.keras.layers.Dropout(0.5),\n#     tf.keras.layers.Dense(64, activation='relu'),\n#     tf.keras.layers.BatchNormalization(),\n#     tf.keras.layers.Dropout(0.5),\n#     tf.keras.layers.Dense(64, activation='relu'),\n# #     tf.keras.layers.BatchNormalization(),\n# #     tf.keras.layers.Dense(64, activation='linear'),\n#     tf.keras.layers.Dense(len(words), activation='softmax')\n# ])\n# # model = tf.keras.Sequential([\n# #     tf.keras.layers.Dense(64, input_dim=14),\n# #     tf.keras.layers.BatchNormalization(),\n# #     tf.keras.layers.Activation('tanh'),\n# #     tf.keras.layers.Dropout(0.5),\n# #     tf.keras.layers.Dense(64),\n# #     tf.keras.layers.BatchNormalization(),\n# #     tf.keras.layers.Activation('tanh'),\n# #     tf.keras.layers.Dropout(0.5),\n# #     tf.keras.layers.Dense(2),\n# #     tf.keras.layers.BatchNormalization(),\n# #     tf.keras.layers.Activation('softmax')\n# # ])\n# # model = Sequential()\n# # activ = 'relu'\n# # model.add(tf.keras.layers.Conv2D(64, (1, 3), strides=(1, 1), padding='same', activation=activ,input_shape=(130, 51, 225)))\n# # model.add(tf.keras.layers.Conv2D(64, (1, 3), strides=(1, 1), padding='same', activation=activ))\n# # #model.add(BatchNormalization(axis = 3))\n# # model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 2) ))\n\n# # model.add(tf.keras.layers.Conv2D(128, (1, 3), strides=(1, 1), padding='same', activation=activ))\n# # model.add(tf.keras.layers.Conv2D(128, (1, 3), strides=(1, 1), padding='same', activation=activ))\n# # model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 2)))\n\n# # model.add(tf.keras.layers.Conv2D(256, (1, 3), strides=(1, 1), padding='same', activation=activ))\n# # model.add(tf.keras.layers.Conv2D(256, (1, 3), strides=(1, 1), padding='same', activation=activ ))\n# # model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 2)))\n# # model.add(tf.keras.layers.Dropout(.5))\n# # A = X_train.shape\n# # model.add(tf.keras.layers.Flatten())\n# # model.add(tf.keras.layers.Dense(int(A[1] * 1/4.), activation=activ))\n# # model.add(tf.keras.layers.Dropout(.5))\n\n# # model.add(tf.keras.layers.Dense(len(words), activation='softmax'))\n\n# optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.003)\n# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n# # Set up early stopping\n# early_stopping = tf.keras.callbacks.EarlyStopping(\n#     monitor='val_loss',  # Metric to monitor for early stopping\n#     mode='min',  # Set mode to 'min' for minimizing the metric\n#     patience=10,  # Number of epochs with no improvement before stopping\n#     restore_best_weights=True,  # Restore the best model weights\n#     verbose=1\n# )","metadata":{"execution":{"iopub.status.busy":"2023-10-20T16:34:37.577553Z","iopub.execute_input":"2023-10-20T16:34:37.578258Z","iopub.status.idle":"2023-10-20T16:34:37.629052Z","shell.execute_reply.started":"2023-10-20T16:34:37.578209Z","shell.execute_reply":"2023-10-20T16:34:37.628199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as ts\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n    tf.keras.layers.Dense(128),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Activation('tanh'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(64),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Activation('tanh'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(len(words)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Activation('softmax')\n])\n# model = tf.keras.Sequential([\n#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n#     tf.keras.layers.Dense(32, activation='relu'),\n#     tf.keras.layers.Dense(len(words), activation='softmax')\n# ])\n# model = tf.keras.Sequential([\n#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n#     tf.keras.layers.BatchNormalization(),\n#     tf.keras.layers.Dense(64, activation='linear'),\n#     tf.keras.layers.BatchNormalization(),\n#      tf.keras.layers.Dropout(0.2),\n#     tf.keras.layers.Dense(64, activation='linear'),\n#     tf.keras.layers.Dense(len(words), activation='softmax')\n# ])\n# Compile the model\nimport tensorflow as ts\n# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\noptimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0003)\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['categorical_accuracy'])\n# Set up early stopping\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_categorical_accuracy',  # Metric to monitor for early stopping\n    mode='max',  # Set mode to 'min' for minimizing the metric\n    patience=30,  # Number of epochs with no improvement before stopping\n    restore_best_weights=True,  # Restore the best model weights\n    verbose=1\n)\ndef scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        return lr * 0.9 ** (epoch // 10000)\n\n# Create the LearningRateScheduler callback\ncallback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n\nes=tf.keras.callbacks.EarlyStopping( monitor=\"val_loss\", patience=1,\n                                     verbose=1,  restore_best_weights=True)\nrlronp=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_categorical_accuracy\", factor=0.5, patience=3,\n                                             verbose=1,mode = 'max')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:09:57.590734Z","iopub.execute_input":"2023-10-27T03:09:57.591945Z","iopub.status.idle":"2023-10-27T03:09:57.663998Z","shell.execute_reply.started":"2023-10-27T03:09:57.591906Z","shell.execute_reply":"2023-10-27T03:09:57.662932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the schedule function\ndef scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        return lr * 0.9 ** (epoch // 10000)\n\n# Create the LearningRateScheduler callback\ncallback = tf.keras.callbacks.LearningRateScheduler(scheduler)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:35:13.323241Z","iopub.execute_input":"2023-10-27T02:35:13.323700Z","iopub.status.idle":"2023-10-27T02:35:13.329367Z","shell.execute_reply.started":"2023-10-27T02:35:13.323664Z","shell.execute_reply":"2023-10-27T02:35:13.328463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# es=tf.keras.callbacks.EarlyStopping( monitor=\"val_loss\", patience=1,\n#                                      verbose=1,  restore_best_weights=True)\n# rlronp=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=3,\n#                                              verbose=1,mode = 'min')","metadata":{"execution":{"iopub.status.busy":"2023-10-20T21:20:04.902410Z","iopub.execute_input":"2023-10-20T21:20:04.902996Z","iopub.status.idle":"2023-10-20T21:20:04.910829Z","shell.execute_reply.started":"2023-10-20T21:20:04.902950Z","shell.execute_reply":"2023-10-20T21:20:04.909594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_training_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200,callbacks=[early_stopping,rlronp,callback])","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:01.932654Z","iopub.execute_input":"2023-10-27T03:10:01.933099Z","iopub.status.idle":"2023-10-27T03:57:12.434940Z","shell.execute_reply.started":"2023-10-27T03:10:01.933065Z","shell.execute_reply":"2023-10-27T03:57:12.433800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation_history = model.evaluate(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:57:12.437319Z","iopub.execute_input":"2023-10-27T03:57:12.438068Z","iopub.status.idle":"2023-10-27T03:57:41.453962Z","shell.execute_reply.started":"2023-10-27T03:57:12.438027Z","shell.execute_reply":"2023-10-27T03:57:41.453100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation_history = model.evaluate(X_test, y_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:57:41.455852Z","iopub.execute_input":"2023-10-27T03:57:41.456659Z","iopub.status.idle":"2023-10-27T03:57:44.870182Z","shell.execute_reply.started":"2023-10-27T03:57:41.456612Z","shell.execute_reply":"2023-10-27T03:57:44.869240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n\n\n    # Get metric values using metric names as identifiers.\n    metric_value_1 = model_training_history.history[metric_name_1]\n    metric_value_2 = model_training_history.history[metric_name_2]\n\n    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n    epochs = range(len(metric_value_1))\n\n    # Plot the Graph.\n    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n\n    # Add title to the plot.\n    plt.title(str(plot_name))\n\n    # Add legend to the plot.\n    plt.legend()\n# Visualize the training and validation loss metrices.\nplot_metric(model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:02:05.911628Z","iopub.execute_input":"2023-10-27T03:02:05.912478Z","iopub.status.idle":"2023-10-27T03:02:06.322734Z","shell.execute_reply.started":"2023-10-27T03:02:05.912437Z","shell.execute_reply":"2023-10-27T03:02:06.321525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the training and validation accuracy metrices.\nplot_metric(model_training_history, 'categorical_accuracy', 'val_categorical_accuracy', 'Total Accuracy vs Total Validation Accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:02:12.843237Z","iopub.execute_input":"2023-10-27T03:02:12.843655Z","iopub.status.idle":"2023-10-27T03:02:13.180603Z","shell.execute_reply.started":"2023-10-27T03:02:12.843623Z","shell.execute_reply":"2023-10-27T03:02:13.179400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicted sign\nres = model.predict(X_test)\nwords[np.argmax(res[1])]","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:02:18.085818Z","iopub.execute_input":"2023-10-27T03:02:18.086637Z","iopub.status.idle":"2023-10-27T03:02:21.308459Z","shell.execute_reply.started":"2023-10-27T03:02:18.086600Z","shell.execute_reply":"2023-10-27T03:02:21.307365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Real sign\nwords[np.argmax(y_test[1])]","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:02:21.311160Z","iopub.execute_input":"2023-10-27T03:02:21.311516Z","iopub.status.idle":"2023-10-27T03:02:21.318126Z","shell.execute_reply.started":"2023-10-27T03:02:21.311485Z","shell.execute_reply":"2023-10-27T03:02:21.316892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the loss and accuracy from model_evaluation_history.\nmodel_evaluation_loss, model_evaluation_accuracy = model_evaluation_history","metadata":{"execution":{"iopub.status.busy":"2023-10-20T12:49:04.356898Z","iopub.execute_input":"2023-10-20T12:49:04.357374Z","iopub.status.idle":"2023-10-20T12:49:04.361893Z","shell.execute_reply.started":"2023-10-20T12:49:04.357336Z","shell.execute_reply":"2023-10-20T12:49:04.361160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat = model.predict(X_test)\ndef get_key_by_value(dictionary, value):\n    for key, val in dictionary.items():\n        if val == value:\n            return key\n    return None\nytrue = np.argmax(y_test, axis=1).tolist()\nyhat = np.argmax(yhat, axis=1).tolist()\n\ny = []\nfor v in ytrue:\n    y.append(get_key_by_value(label_map, v))\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:02:27.638741Z","iopub.execute_input":"2023-10-27T03:02:27.639970Z","iopub.status.idle":"2023-10-27T03:02:29.166387Z","shell.execute_reply.started":"2023-10-27T03:02:27.639922Z","shell.execute_reply":"2023-10-27T03:02:29.165439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred = []\nfor v in yhat:\n    ypred.append(get_key_by_value(label_map, v))\nprint(ypred)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:02:31.174987Z","iopub.execute_input":"2023-10-27T03:02:31.176466Z","iopub.status.idle":"2023-10-27T03:02:31.196949Z","shell.execute_reply.started":"2023-10-27T03:02:31.176416Z","shell.execute_reply":"2023-10-27T03:02:31.195450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Assuming y and ypred are your target labels and predicted labels, respectively\n\ny_subset = y\nypred_subset = ypred\n\n# Get unique class labels\nclass_labels = np.unique(y_subset)\n\n# Compute confusion matrix\ncm = confusion_matrix(y_subset, ypred_subset, labels=class_labels)\n# Create a DataFrame from the confusion matrix\ndf_cm = pd.DataFrame(cm, index=class_labels, columns=class_labels)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\n# Plot the confusion matrix\nplt.figure(figsize=(len(words), len(words)*0.8))\nsns.set(font_scale=1.3)  # for label size\nsns.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt=\"d\", annot_kws={\"size\": 12})\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:02:32.684274Z","iopub.execute_input":"2023-10-27T03:02:32.684711Z","iopub.status.idle":"2023-10-27T03:02:59.295536Z","shell.execute_reply.started":"2023-10-27T03:02:32.684676Z","shell.execute_reply":"2023-10-27T03:02:59.294143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the string date format.\n# Get the current Date and Time in a DateTime Object.\n# Convert the DateTime object to string according to the style mentioned in date_time_format string.\ndate_time_format = '%Y_%m_%d__%H_%M_%S'\ncurrent_date_time_dt = dt.datetime.now()\ncurrent_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n\n# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\nmodel_file_name = f'Tur_Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n\nos.makedirs('/kaggle/working/Model',exist_ok=True)\n# Save your Model.\nmodelPath = f'/kaggle/working/Model/{model_file_name}'\nmodel.save(modelPath)","metadata":{"execution":{"iopub.status.busy":"2023-10-20T12:49:50.547127Z","iopub.execute_input":"2023-10-20T12:49:50.547485Z","iopub.status.idle":"2023-10-20T12:49:50.604992Z","shell.execute_reply.started":"2023-10-20T12:49:50.547457Z","shell.execute_reply":"2023-10-20T12:49:50.604100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the libraries\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Load the H5 model\nmodel = keras.models.load_model(modelPath)\n\n# Convert the model to TensorFlow Lite\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\nconverter._experimental_lower_tensor_list_ops = False\ntflite_model = converter.convert()\n\n# Save the TensorFlow Lite model\nwith open(\"/kaggle/working/TurkishModel.tflite\", \"wb\") as f:\n  f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2023-10-20T12:49:57.180707Z","iopub.execute_input":"2023-10-20T12:49:57.181075Z","iopub.status.idle":"2023-10-20T12:50:50.687211Z","shell.execute_reply.started":"2023-10-20T12:49:57.181038Z","shell.execute_reply":"2023-10-20T12:50:50.686068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}