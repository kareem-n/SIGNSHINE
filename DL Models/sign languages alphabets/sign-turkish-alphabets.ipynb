{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1186303,"sourceType":"datasetVersion","datasetId":674494}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Add Python module called Mediapipe\n!pip install mediapipe","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:06:31.503153Z","iopub.execute_input":"2023-09-21T08:06:31.503805Z","iopub.status.idle":"2023-09-21T08:06:50.350046Z","shell.execute_reply.started":"2023-09-21T08:06:31.503772Z","shell.execute_reply":"2023-09-21T08:06:50.348695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:06:50.352309Z","iopub.execute_input":"2023-09-21T08:06:50.352683Z","iopub.status.idle":"2023-09-21T08:07:01.690135Z","shell.execute_reply.started":"2023-09-21T08:06:50.352648Z","shell.execute_reply":"2023-09-21T08:07:01.688904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the much needed stuff for training\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport mediapipe as mp\nimport os\nimport csv\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.utils import to_categorical\nimport seaborn as sns\n# Make numpy values easier to read.\nnp.set_printoptions(precision=3, suppress=True)\n\n# Checking Tensorflow Version\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:07:01.693643Z","iopub.execute_input":"2023-09-21T08:07:01.694269Z","iopub.status.idle":"2023-09-21T08:07:03.111983Z","shell.execute_reply.started":"2023-09-21T08:07:01.694229Z","shell.execute_reply":"2023-09-21T08:07:03.110773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to Extract Feature from images or Frame\ndef extract_feature(input_image):\n    mp_hands = mp.solutions.hands\n    mp_drawing = mp.solutions.drawing_utils \n    image = cv.imread(input_image)\n    \n    with mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.1) as hands:\n        while True:\n            results = hands.process(cv.flip(cv.cvtColor(image, cv.COLOR_BGR2RGB), 1))\n            image_height, image_width, _ = image.shape\n            # Print handedness (left v.s. right hand).\n            # Caution : Uncomment these print command will resulting long log of mediapipe log\n            #print(f'Handedness of {input_image}:')\n            #print(results.multi_handedness)\n\n            # Draw hand landmarks of each hand.\n            # Caution : Uncomment these print command will resulting long log of mediapipe log\n            #print(f'Hand landmarks of {input_image}:')\n            if not results.multi_hand_landmarks:\n                # Here we will set whole landmarks into zero as no handpose detected\n                # in a picture wanted to extract.\n                \n                # Wrist Hand\n                hand_data=np.zeros(10)\n                \n                # Set image to Zero\n                annotated_image = 0\n\n                # Return Whole Landmark and Image\n                return (hand_data,\n                        annotated_image)\n            \n            annotated_image = cv.flip(image.copy(), 1)\n            hand_data = []\n\n            # Iterate over all hands detected in the image.\n            for hand_landmarks in results.multi_hand_landmarks:\n\n                # Extract the coordinates of all 21 hand landmarks.\n                landmark_coordinates = []\n                for landmark in mp_hands.HandLandmark:\n                    landmark_coordinates.append(hand_landmarks.landmark[landmark].x * image_width)\n                    landmark_coordinates.append(hand_landmarks.landmark[landmark].y * image_height)\n                    landmark_coordinates.append(hand_landmarks.landmark[landmark].z)\n                mp_drawing.draw_landmarks(annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n\n                # Add the coordinates of all 21 hand landmarks for the current hand to the new array.\n                hand_data.extend(landmark_coordinates)\n            #If less than two hands are detected, fill the rest of the array with zeros.\n            if len(results.multi_hand_landmarks) < 2:\n                num_missing_hands = 2 - len(results.multi_hand_landmarks)\n                num_missing_coordinates = num_missing_hands * 21 * 3  # 21 landmarks * 3 coordinates (x, y, z)\n                hand_data.extend([0] * num_missing_coordinates)\n\n            hand_data = np.array(hand_data)\n            return  (hand_data, annotated_image)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:07:03.114753Z","iopub.execute_input":"2023-09-21T08:07:03.115135Z","iopub.status.idle":"2023-09-21T08:07:03.129266Z","shell.execute_reply.started":"2023-09-21T08:07:03.115104Z","shell.execute_reply":"2023-09-21T08:07:03.127871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nimport os\n\ndef toCSV(filecsv, class_type, hand_data):\n    # Convert elements of hand_data to string\n    hand_data = list(map(str, hand_data))\n    \n    # Check if file exists\n    if os.path.isfile(filecsv):\n        with open(filecsv, 'a+', newline='') as file:\n            writer = csv.writer(file)\n            # Write the class type and hand data to the file\n            writer.writerow([class_type] + hand_data)\n    else:\n        with open(filecsv, 'w', newline='') as file:\n            writer = csv.writer(file)\n            # Write the header to the file\n            header = [\"class_type\"] + [\"value\"+str(i) for i in range(1, 127)]\n            writer.writerow(header)\n            # Write the class type and hand data to the file\n            writer.writerow([class_type] + hand_data)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:07:03.130801Z","iopub.execute_input":"2023-09-21T08:07:03.131249Z","iopub.status.idle":"2023-09-21T08:07:03.154752Z","shell.execute_reply.started":"2023-09-21T08:07:03.131211Z","shell.execute_reply":"2023-09-21T08:07:03.153379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Your existing code...\npaths = \"/kaggle/input/tr-sign-language/tr_signLanguage_dataset/train/\"\ncsv_path = \"hands_SIBI_training.csv\"\n\nif os.path.exists(csv_path):\n    print(\"CSV File does exist, going delete before start extraction and replace it with new\")\n    os.remove(csv_path)\nelse:\n    print(\"The CSV file does not exist\", csv_path, \",Going Create after Extraction\")\n    \nfor dirlist in os.listdir(paths):\n    for root, directories, filenames in os.walk(os.path.join(paths, dirlist)):\n        print(\"Inside Folder\", dirlist, \"Consist :\", len(filenames), \"Imageset\")\n        for filename in filenames:\n            if filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n                # Assuming extract_feature returns an array of 126 values\n                (hand_data, output_IMG) =  extract_feature(os.path.join(root, filename))\n                if len(hand_data) == 126:\n                    toCSV(csv_path, dirlist, hand_data)\n                else :\n                    print(os.path.join(root, filename), \"Hand does not have landmarks\")\n\nprint(\"===================Feature Extraction for TRAINING is Completed===================\")","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:07:03.156361Z","iopub.execute_input":"2023-09-21T08:07:03.15675Z","iopub.status.idle":"2023-09-21T09:26:55.083085Z","shell.execute_reply.started":"2023-09-21T08:07:03.156719Z","shell.execute_reply":"2023-09-21T09:26:55.08133Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Your existing code...\npaths = \"/kaggle/input/tr-sign-language/tr_signLanguage_dataset/test/\"\ncsv_path = \"hands_SIBI_validation.csv\"\n\nif os.path.exists(csv_path):\n    print(\"CSV File does exist, going delete before start extraction and replace it with new\")\n    os.remove(csv_path)\nelse:\n    print(\"The CSV file does not exist\", csv_path, \",Going Create after Extraction\")\n    \nfor dirlist in os.listdir(paths):\n    for root, directories, filenames in os.walk(os.path.join(paths, dirlist)):\n        print(\"Inside Folder\", dirlist, \"Consist :\", len(filenames), \"Imageset\")\n        for filename in filenames:\n            if filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n                # Assuming extract_feature returns an array of 126 values\n                (hand_data, output_IMG) =  extract_feature(os.path.join(root, filename))\n                if len(hand_data) == 126:\n                    toCSV(csv_path, dirlist, hand_data)\n                else :\n                    print(os.path.join(root, filename), \"Hand does not have landmarks\")\n\nprint(\"===================Feature Extraction for Testing is Completed===================\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:37:03.617731Z","iopub.execute_input":"2021-08-24T14:37:03.618052Z","iopub.status.idle":"2021-08-24T14:37:37.089819Z","shell.execute_reply.started":"2021-08-24T14:37:03.618017Z","shell.execute_reply":"2021-08-24T14:37:37.087703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read CSV file for Training the model using Pandas\ndf_train = pd.read_csv(\"hands_SIBI_training.csv\", header=0)\n\n# First we must sort the values of the dataset according to the Alphabets\ndf_train = df_train.sort_values(by=[\"class_type\"])\n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:58:29.888189Z","iopub.execute_input":"2023-09-21T09:58:29.88919Z","iopub.status.idle":"2023-09-21T09:58:31.391853Z","shell.execute_reply.started":"2023-09-21T09:58:29.889149Z","shell.execute_reply":"2023-09-21T09:58:31.390434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_counts = df_train['class_type'].value_counts()\n# class_counts","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:58:35.429031Z","iopub.execute_input":"2023-09-21T09:58:35.429456Z","iopub.status.idle":"2023-09-21T09:58:35.444728Z","shell.execute_reply.started":"2023-09-21T09:58:35.429423Z","shell.execute_reply":"2023-09-21T09:58:35.44362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_train['class_type'].unique())","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:58:36.035496Z","iopub.execute_input":"2023-09-21T09:58:36.036083Z","iopub.status.idle":"2023-09-21T09:58:36.047846Z","shell.execute_reply.started":"2023-09-21T09:58:36.036044Z","shell.execute_reply":"2023-09-21T09:58:36.046539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['class_type'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:58:36.96048Z","iopub.execute_input":"2023-09-21T09:58:36.960899Z","iopub.status.idle":"2023-09-21T09:58:36.972856Z","shell.execute_reply.started":"2023-09-21T09:58:36.960869Z","shell.execute_reply":"2023-09-21T09:58:36.971516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lst = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n#        'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z', 'del', 'nothing',\n#        'space']\n\n# dict_lst = {k: v for v, k in enumerate(lst)}\n\n# print(dict_lst)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:59:08.893564Z","iopub.execute_input":"2023-09-21T09:59:08.894916Z","iopub.status.idle":"2023-09-21T09:59:08.901938Z","shell.execute_reply.started":"2023-09-21T09:59:08.894875Z","shell.execute_reply":"2023-09-21T09:59:08.900722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read CSV file for Validation or Testing the Model using Pandas\ndf_test = pd.read_csv(\"hands_SIBI_validation.csv\", header=0)\n\n# First we must sort the values of the dataset according to the Alphabets\ndf_test = df_test.sort_values(by=[\"class_type\"])\n\ndf_test","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:30:24.762455Z","iopub.execute_input":"2023-09-21T09:30:24.763582Z","iopub.status.idle":"2023-09-21T09:30:24.770696Z","shell.execute_reply.started":"2023-09-21T09:30:24.763537Z","shell.execute_reply":"2023-09-21T09:30:24.769535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put Categorical using Pandas\ndf_train[\"class_type\"] = pd.Categorical(df_train[\"class_type\"])\ndf_train[\"class_type\"] = df_train.class_type.cat.codes\n\ndf_test[\"class_type\"] = pd.Categorical(df_test[\"class_type\"])\ndf_test[\"class_type\"] = df_test.class_type.cat.codes","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:30:24.772554Z","iopub.execute_input":"2023-09-21T09:30:24.773028Z","iopub.status.idle":"2023-09-21T09:30:24.790672Z","shell.execute_reply.started":"2023-09-21T09:30:24.772986Z","shell.execute_reply":"2023-09-21T09:30:24.789253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train.drop('class_type', axis=1)\ny=df_train[\"class_type\"]\n\nx_test = df_test.drop('class_type', axis=1)\ny_test=df_test[\"class_type\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:30:24.791899Z","iopub.execute_input":"2023-09-21T09:30:24.792504Z","iopub.status.idle":"2023-09-21T09:30:24.818396Z","shell.execute_reply.started":"2023-09-21T09:30:24.792453Z","shell.execute_reply":"2023-09-21T09:30:24.816893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming X is your data and y are your labels\nx_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:30:24.89096Z","iopub.execute_input":"2023-09-21T09:30:24.891369Z","iopub.status.idle":"2023-09-21T09:30:24.935412Z","shell.execute_reply.started":"2023-09-21T09:30:24.891337Z","shell.execute_reply":"2023-09-21T09:30:24.934127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx_train = np.array(x_train)\nx_val = np.array(x_val)\nx_test = np.array(x_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:30:25.215624Z","iopub.execute_input":"2023-09-21T09:30:25.216047Z","iopub.status.idle":"2023-09-21T09:30:25.2361Z","shell.execute_reply.started":"2023-09-21T09:30:25.216017Z","shell.execute_reply":"2023-09-21T09:30:25.235002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Array Shape before transformation\nprint(x_train.shape)\nprint(x_test.shape)\nprint(x_val.shape)\n\n# Since the array shape is 1x1, we must turn it into 1x10x1 so we can feed it into the model\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\nx_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n\n# Check Array Shape after transformation\nprint(x_train.shape)\nprint(x_test.shape)\nprint(x_val.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:30:25.824838Z","iopub.execute_input":"2023-09-21T09:30:25.825565Z","iopub.status.idle":"2023-09-21T09:30:25.833062Z","shell.execute_reply.started":"2023-09-21T09:30:25.825529Z","shell.execute_reply":"2023-09-21T09:30:25.831884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check sample train and test features\nprint(x_train[0])\nprint(x_test[7])","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:30:26.427022Z","iopub.execute_input":"2023-09-21T09:30:26.428434Z","iopub.status.idle":"2023-09-21T09:30:26.43815Z","shell.execute_reply.started":"2023-09-21T09:30:26.428394Z","shell.execute_reply":"2023-09-21T09:30:26.436964Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of classes according standard Indonesian Language Alphabets\nnum_classes = 26\n\n# Using the Keras.Utils to put the label categorically \ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\ny_val = to_categorical(y_val, num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:30:27.241182Z","iopub.execute_input":"2023-09-21T09:30:27.241635Z","iopub.status.idle":"2023-09-21T09:30:27.248875Z","shell.execute_reply.started":"2023-09-21T09:30:27.241575Z","shell.execute_reply":"2023-09-21T09:30:27.247611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# Name of the model\nmodel_name = \"best_model.h5\"\n\n# ModelCheckpoint callback\ncheckpoint = ModelCheckpoint(model_name,\n                             monitor=\"val_loss\",\n                             mode=\"min\",\n                             save_best_only=True,\n                             verbose=1)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n                                            patience=2,  # Reduced patience to 2\n                                            verbose=1,\n                                            factor=0.3,  # Changed factor to 0.3\n                                            min_lr=0.00001)  # Added minimum learning rate","metadata":{"execution":{"iopub.status.busy":"2023-09-21T10:02:02.988723Z","iopub.execute_input":"2023-09-21T10:02:02.989135Z","iopub.status.idle":"2023-09-21T10:02:02.997857Z","shell.execute_reply.started":"2023-09-21T10:02:02.989104Z","shell.execute_reply":"2023-09-21T10:02:02.996484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import regularizers\nfrom tensorflow.keras.optimizers import Adam\n\n# One Dimensional Convolutional Neural Network model, Train will be feed to 1 Dimension Convolutional Neural Network\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\", input_shape=x_train.shape[1:3]),\n    tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n    tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n    tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n    tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    tf.keras.layers.Dropout(rate=0.2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'), \n    tf.keras.layers.Dense(num_classes, activation='softmax')])\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T10:02:03.296554Z","iopub.execute_input":"2023-09-21T10:02:03.297004Z","iopub.status.idle":"2023-09-21T10:02:03.454355Z","shell.execute_reply.started":"2023-09-21T10:02:03.296968Z","shell.execute_reply":"2023-09-21T10:02:03.452755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train the Model\nhistory=model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_val, y_val),callbacks=[checkpoint,learning_rate_reduction])","metadata":{"execution":{"iopub.status.busy":"2023-09-21T10:02:04.174195Z","iopub.execute_input":"2023-09-21T10:02:04.174589Z","iopub.status.idle":"2023-09-21T10:02:04.231144Z","shell.execute_reply.started":"2023-09-21T10:02:04.174559Z","shell.execute_reply":"2023-09-21T10:02:04.229537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # One Dimensional Convolutional Neural Network model, Train will be feed to 1 Dimension Convolutional Neural Network\n# model = tf.keras.models.Sequential([\n#     tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\", input_shape=x_train.shape[1:3]),\n#     tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.MaxPooling1D(pool_size=2),\n#     tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.MaxPooling1D(pool_size=2),\n#     tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.MaxPooling1D(pool_size=2),\n#     tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.MaxPooling1D(pool_size=2),\n#     tf.keras.layers.Dropout(rate=0.2),\n#     # Flatten the results to feed into a DNN\n#     tf.keras.layers.Flatten(),\n#     # 512 neuron hidden layer\n#     tf.keras.layers.Dense(512, activation='relu'), \n#     tf.keras.layers.Dense(num_classes, activation='softmax')])\n\n# model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:58:00.749505Z","iopub.execute_input":"2023-09-21T09:58:00.74998Z","iopub.status.idle":"2023-09-21T09:58:00.757053Z","shell.execute_reply.started":"2023-09-21T09:58:00.749946Z","shell.execute_reply":"2023-09-21T09:58:00.755626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:58:01.027032Z","iopub.execute_input":"2023-09-21T09:58:01.027485Z","iopub.status.idle":"2023-09-21T09:58:01.474892Z","shell.execute_reply.started":"2023-09-21T09:58:01.027448Z","shell.execute_reply":"2023-09-21T09:58:01.473567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:58:01.923918Z","iopub.execute_input":"2023-09-21T09:58:01.924994Z","iopub.status.idle":"2023-09-21T09:58:02.323589Z","shell.execute_reply.started":"2023-09-21T09:58:01.924945Z","shell.execute_reply":"2023-09-21T09:58:02.322385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving the model into H5 system file\nsave_model = \"model_tur.h5\"\nmodel.save(save_model)\nprint(\"Model Saved into\", save_model)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:23:41.624138Z","iopub.execute_input":"2023-09-14T09:23:41.62458Z","iopub.status.idle":"2023-09-14T09:23:41.669587Z","shell.execute_reply.started":"2023-09-14T09:23:41.624547Z","shell.execute_reply":"2023-09-14T09:23:41.668691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)\nprint('\\nTest loss:', test_loss)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:58:07.927232Z","iopub.execute_input":"2023-09-21T09:58:07.927657Z","iopub.status.idle":"2023-09-21T09:58:09.194191Z","shell.execute_reply.started":"2023-09-21T09:58:07.927614Z","shell.execute_reply":"2023-09-21T09:58:09.193298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = np.argmax(y_test,axis=1)\ny_pred = model.predict(x_test)\ny_pred = np.argmax(y_pred,axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:58:12.765227Z","iopub.execute_input":"2023-09-21T09:58:12.765633Z","iopub.status.idle":"2023-09-21T09:58:14.391252Z","shell.execute_reply.started":"2023-09-21T09:58:12.765587Z","shell.execute_reply":"2023-09-21T09:58:14.390091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='.3g',cmap='viridis')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:58:14.39578Z","iopub.execute_input":"2023-09-21T09:58:14.396133Z","iopub.status.idle":"2023-09-21T09:58:16.267452Z","shell.execute_reply.started":"2023-09-21T09:58:14.396091Z","shell.execute_reply":"2023-09-21T09:58:16.266459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# Convert the model.\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model_tur.tflite', 'wb') as f:\n  f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:24:45.051894Z","iopub.execute_input":"2023-09-14T09:24:45.052372Z","iopub.status.idle":"2023-09-14T09:24:48.260884Z","shell.execute_reply.started":"2023-09-14T09:24:45.052335Z","shell.execute_reply":"2023-09-14T09:24:48.258987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hard Encode for the Prediction\nclasses = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'R': 16, 'S': 17, 'T': 18, 'U': 19, 'V': 20, 'Y': 21, 'Z': 22, 'del': 23, 'nothing': 24, 'space': 25}","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:59:22.041761Z","iopub.execute_input":"2023-09-21T09:59:22.042315Z","iopub.status.idle":"2023-09-21T09:59:22.050096Z","shell.execute_reply.started":"2023-09-21T09:59:22.042272Z","shell.execute_reply":"2023-09-21T09:59:22.048899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:59:23.352324Z","iopub.execute_input":"2023-09-21T09:59:23.352858Z","iopub.status.idle":"2023-09-21T09:59:23.358049Z","shell.execute_reply.started":"2023-09-21T09:59:23.352822Z","shell.execute_reply":"2023-09-21T09:59:23.356683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directly from Imageset Dataset Testing\n#Load Image and do Feature Extraction\npath_to_image = \"/kaggle/input/tr-sign-language/tr_signLanguage_dataset/test/U/U_0_100.jpg\"\n\n# (wristX, wristY, wristZ,\n#  thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n#  thumb_McpX, thumb_McpY, thumb_McpZ,\n#  thumb_IpX, thumb_IpY, thumb_IpZ,\n#  thumb_TipX, thumb_TipY, thumb_TipZ,\n#  index_McpX, index_McpY, index_McpZ,\n#  index_PipX, index_PipY, index_PipZ,\n#  index_DipX, index_DipY, index_DipZ,\n#  index_TipX, index_TipY, index_TipZ,\n#  middle_McpX, middle_McpY, middle_McpZ,\n#  middle_PipX, middle_PipY, middle_PipZ,\n#  middle_DipX, middle_DipY, middle_DipZ,\n#  middle_TipX, middle_TipY, middle_TipZ,\n#  ring_McpX, ring_McpY, ring_McpZ,\n#  ring_PipX, ring_PipY, ring_PipZ,\n#  ring_DipX, ring_DipY, ring_DipZ,\n#  ring_TipX, ring_TipY, ring_TipZ,\n#  pinky_McpX, pinky_McpY, pinky_McpZ,\n#  pinky_PipX, pinky_PipY, pinky_PipZ,\n#  pinky_DipX, pinky_DipY, pinky_DipZ,\n#  pinky_TipX, pinky_TipY, pinky_TipZ,\n(input_IMG, output_IMG) = extract_feature(path_to_image)\n\n#print(wristX, wristY,\n#      thumb_CmcX, thumb_CmcY, thumb_McpX, thumb_McpY, thumb_IpX, thumb_IpY, thumb_TipX, thumb_TipY,\n#      index_McpX, index_McpY, index_PipX, index_PipY, index_DipX, index_DipY, index_TipX, index_TipY,\n#      middle_McpX, middle_McpY, middle_PipX, middle_PipY, middle_DipX, middle_DipY, middle_TipX, middle_TipY,\n#      ring_McpX, ring_McpY, ring_PipX, ring_PipY, ring_DipX, ring_DipY, ring_TipX, ring_TipY,\n#      pinky_McpX, pinky_McpY, pinky_PipX, pinky_PipY, pinky_DipX, pinky_DipY, pinky_TipX, pinky_TipY)\nplt.axis(\"on\")\nplt.imshow(cv.cvtColor(output_IMG, cv.COLOR_BGR2RGB))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T09:59:55.86372Z","iopub.execute_input":"2023-09-21T09:59:55.864101Z","iopub.status.idle":"2023-09-21T09:59:56.361205Z","shell.execute_reply.started":"2023-09-21T09:59:55.864072Z","shell.execute_reply":"2023-09-21T09:59:56.360361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_IMG=input_IMG.reshape(-1,1)\ninput_IMG = np.expand_dims(input_IMG, axis=0)\ninput_IMG.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-21T10:01:25.829825Z","iopub.execute_input":"2023-09-21T10:01:25.830217Z","iopub.status.idle":"2023-09-21T10:01:25.838701Z","shell.execute_reply.started":"2023-09-21T10:01:25.830189Z","shell.execute_reply":"2023-09-21T10:01:25.837444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the Prediction\nprint(model.predict(input_IMG))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T10:01:27.191647Z","iopub.execute_input":"2023-09-21T10:01:27.19204Z","iopub.status.idle":"2023-09-21T10:01:27.275949Z","shell.execute_reply.started":"2023-09-21T10:01:27.192009Z","shell.execute_reply":"2023-09-21T10:01:27.27467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print prediction using defined Classes\npredictions = model.predict(input_IMG)\npredictions=np.argmax(predictions,axis=1)\nfor alphabets, values in classes.items():\n    if values == predictions[0] :\n        print(\"Possible Alphabet according to the input : \", alphabets)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T10:01:47.8571Z","iopub.execute_input":"2023-09-21T10:01:47.85752Z","iopub.status.idle":"2023-09-21T10:01:47.93837Z","shell.execute_reply.started":"2023-09-21T10:01:47.857489Z","shell.execute_reply":"2023-09-21T10:01:47.937102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}