{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29550,"sourceType":"datasetVersion","datasetId":23079}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Add Python module called Mediapipe\n!pip install mediapipe","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:22:12.427421Z","iopub.execute_input":"2023-09-14T06:22:12.427878Z","iopub.status.idle":"2023-09-14T06:22:31.350384Z","shell.execute_reply.started":"2023-09-14T06:22:12.427839Z","shell.execute_reply":"2023-09-14T06:22:31.348756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:22:31.353470Z","iopub.execute_input":"2023-09-14T06:22:31.353869Z","iopub.status.idle":"2023-09-14T06:22:31.363082Z","shell.execute_reply.started":"2023-09-14T06:22:31.353835Z","shell.execute_reply":"2023-09-14T06:22:31.361724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the much needed stuff for training\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport mediapipe as mp\nimport os\nimport csv\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.utils import to_categorical\nimport seaborn as sns\n# Make numpy values easier to read.\nnp.set_printoptions(precision=3, suppress=True)\n\n# Checking Tensorflow Version\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:22:31.364673Z","iopub.execute_input":"2023-09-14T06:22:31.365092Z","iopub.status.idle":"2023-09-14T06:22:33.151741Z","shell.execute_reply.started":"2023-09-14T06:22:31.365058Z","shell.execute_reply":"2023-09-14T06:22:33.150492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to Extract Feature from images or Frame\ndef extract_feature(input_image):\n    mp_hands = mp.solutions.hands\n    mp_drawing = mp.solutions.drawing_utils \n    image = cv.imread(input_image)\n    with mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.1) as hands:\n        while True:\n            results = hands.process(cv.flip(cv.cvtColor(image, cv.COLOR_BGR2RGB), 1))\n            image_height, image_width, _ = image.shape\n            # Print handedness (left v.s. right hand).\n            # Caution : Uncomment these print command will resulting long log of mediapipe log\n            #print(f'Handedness of {input_image}:')\n            #print(results.multi_handedness)\n\n            # Draw hand landmarks of each hand.\n            # Caution : Uncomment these print command will resulting long log of mediapipe log\n            #print(f'Hand landmarks of {input_image}:')\n            if not results.multi_hand_landmarks:\n                # Here we will set whole landmarks into zero as no handpose detected\n                # in a picture wanted to extract.\n                \n                # Wrist Hand\n                wristX = 0\n                wristY = 0\n                wristZ = 0\n                \n                # Thumb Finger\n                thumb_CmcX = 0\n                thumb_CmcY = 0\n                thumb_CmcZ = 0\n                \n                thumb_McpX = 0\n                thumb_McpY = 0\n                thumb_McpZ = 0\n                \n                thumb_IpX = 0\n                thumb_IpY = 0\n                thumb_IpZ = 0\n                \n                thumb_TipX = 0\n                thumb_TipY = 0\n                thumb_TipZ = 0\n\n                # Index Finger\n                index_McpX = 0\n                index_McpY = 0\n                index_McpZ = 0\n                \n                index_PipX = 0\n                index_PipY = 0\n                index_PipZ = 0\n                \n                index_DipX = 0\n                index_DipY = 0\n                index_DipZ = 0\n                \n                index_TipX = 0\n                index_TipY = 0\n                index_TipZ = 0\n\n                # Middle Finger\n                middle_McpX = 0\n                middle_McpY = 0\n                middle_McpZ = 0\n                \n                middle_PipX = 0\n                middle_PipY = 0\n                middle_PipZ = 0\n                \n                middle_DipX = 0\n                middle_DipY = 0\n                middle_DipZ = 0\n                \n                middle_TipX = 0\n                middle_TipY = 0\n                middle_TipZ = 0\n\n                # Ring Finger\n                ring_McpX = 0\n                ring_McpY = 0\n                ring_McpZ = 0\n                \n                ring_PipX = 0\n                ring_PipY = 0\n                ring_PipZ = 0\n                \n                ring_DipX = 0\n                ring_DipY = 0\n                ring_DipZ = 0\n                \n                ring_TipX = 0\n                ring_TipY = 0\n                ring_TipZ = 0\n\n                # Pinky Finger\n                pinky_McpX = 0\n                pinky_McpY = 0\n                pinky_McpZ = 0\n                \n                pinky_PipX = 0\n                pinky_PipY = 0\n                pinky_PipZ = 0\n                \n                pinky_DipX = 0\n                pinky_DipY = 0\n                pinky_DipZ = 0\n                \n                pinky_TipX = 0\n                pinky_TipY = 0\n                pinky_TipZ = 0\n                \n                # Set image to Zero\n                annotated_image = 0\n\n                # Return Whole Landmark and Image\n                return (wristX, wristY, wristZ,\n                        thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n                        thumb_McpX, thumb_McpY, thumb_McpZ,\n                        thumb_IpX, thumb_IpY, thumb_IpZ,\n                        thumb_TipX, thumb_TipY, thumb_TipZ,\n                        index_McpX, index_McpY, index_McpZ,\n                        index_PipX, index_PipY, index_PipZ,\n                        index_DipX, index_DipY, index_DipZ,\n                        index_TipX, index_TipY, index_TipZ,\n                        middle_McpX, middle_McpY, middle_McpZ,\n                        middle_PipX, middle_PipY, middle_PipZ,\n                        middle_DipX, middle_DipY, middle_DipZ,\n                        middle_TipX, middle_TipY, middle_TipZ,\n                        ring_McpX, ring_McpY, ring_McpZ,\n                        ring_PipX, ring_PipY, ring_PipZ,\n                        ring_DipX, ring_DipY, ring_DipZ,\n                        ring_TipX, ring_TipY, ring_TipZ,\n                        pinky_McpX, pinky_McpY, pinky_McpZ,\n                        pinky_PipX, pinky_PipY, pinky_PipZ,\n                        pinky_DipX, pinky_DipY, pinky_DipZ,\n                        pinky_TipX, pinky_TipY, pinky_TipZ,\n                        annotated_image)\n            \n            annotated_image = cv.flip(image.copy(), 1)\n            for hand_landmarks in results.multi_hand_landmarks:\n                # Wrist Hand /  Pergelangan Tangan\n                wristX = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * image_width\n                wristY = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * image_height\n                wristZ = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].z\n\n                # Thumb Finger / Ibu Jari\n                thumb_CmcX = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_CMC].x * image_width\n                thumb_CmcY = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_CMC].y * image_height\n                thumb_CmcZ = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_CMC].z\n                \n                thumb_McpX = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP].x * image_width\n                thumb_McpY = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP].y * image_height\n                thumb_McpZ = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP].z\n                \n                thumb_IpX = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP].x * image_width\n                thumb_IpY = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP].y * image_height\n                thumb_IpZ = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP].z\n                \n                thumb_TipX = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x * image_width\n                thumb_TipY = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y * image_height\n                thumb_TipZ = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].z\n\n                # Index Finger / Jari Telunjuk\n                index_McpX = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP].x * image_width\n                index_McpY = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP].y * image_height\n                index_McpZ = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP].z\n                \n                index_PipX = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].x * image_width\n                index_PipY = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].y * image_height\n                index_PipZ = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].z\n                \n                index_DipX = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_DIP].x * image_width\n                index_DipY = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_DIP].y * image_height\n                index_DipZ = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_DIP].z\n                \n                index_TipX = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width\n                index_TipY = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height\n                index_TipZ = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].z\n\n                # Middle Finger / Jari Tengah\n                middle_McpX = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP].x * image_width\n                middle_McpY = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP].y * image_height\n                middle_McpZ = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP].z\n                \n                middle_PipX = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP].x * image_width\n                middle_PipY = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP].y * image_height\n                middle_PipZ = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP].z\n                \n                middle_DipX = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_DIP].x * image_width\n                middle_DipY = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_DIP].y * image_height\n                middle_DipZ = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_DIP].z\n                \n                middle_TipX = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].x * image_width\n                middle_TipY = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y * image_height\n                middle_TipZ = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].z\n\n                # Ring Finger / Jari Cincin\n                ring_McpX = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP].x * image_width\n                ring_McpY = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP].y * image_height\n                ring_McpZ = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP].z\n                \n                ring_PipX = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_PIP].x * image_width\n                ring_PipY = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_PIP].y * image_height\n                ring_PipZ = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_PIP].z\n                \n                ring_DipX = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_DIP].x * image_width\n                ring_DipY = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_DIP].y * image_height\n                ring_DipZ = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_DIP].z\n                \n                ring_TipX = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP].x * image_width\n                ring_TipY = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP].y * image_height\n                ring_TipZ = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP].z\n\n                # Pinky Finger / Jari Kelingking\n                pinky_McpX = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP].x * image_width\n                pinky_McpY = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP].y * image_height\n                pinky_McpZ = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP].z\n                \n                pinky_PipX = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_PIP].x * image_width\n                pinky_PipY = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_PIP].y * image_height\n                pinky_PipZ = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_PIP].z\n                \n                pinky_DipX = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_DIP].x * image_width\n                pinky_DipY = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_DIP].y * image_height\n                pinky_DipZ = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_DIP].z\n                \n                pinky_TipX = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP].x * image_width\n                pinky_TipY = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP].y * image_height\n                pinky_TipZ = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP].z\n\n                # Draw the Skeleton\n                mp_drawing.draw_landmarks(annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n                \n            return (wristX, wristY, wristZ,\n                    thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n                    thumb_McpX, thumb_McpY, thumb_McpZ,\n                    thumb_IpX, thumb_IpY, thumb_IpZ,\n                    thumb_TipX, thumb_TipY, thumb_TipZ,\n                    index_McpX, index_McpY, index_McpZ,\n                    index_PipX, index_PipY, index_PipZ,\n                    index_DipX, index_DipY, index_DipZ,\n                    index_TipX, index_TipY, index_TipZ,\n                    middle_McpX, middle_McpY, middle_McpZ,\n                    middle_PipX, middle_PipY, middle_PipZ,\n                    middle_DipX, middle_DipY, middle_DipZ,\n                    middle_TipX, middle_TipY, middle_TipZ,\n                    ring_McpX, ring_McpY, ring_McpZ,\n                    ring_PipX, ring_PipY, ring_PipZ,\n                    ring_DipX, ring_DipY, ring_DipZ,\n                    ring_TipX, ring_TipY, ring_TipZ,\n                    pinky_McpX, pinky_McpY, pinky_McpZ,\n                    pinky_PipX, pinky_PipY, pinky_PipZ,\n                    pinky_DipX, pinky_DipY, pinky_DipZ,\n                    pinky_TipX, pinky_TipY, pinky_TipZ,\n                    annotated_image)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:22:37.755014Z","iopub.execute_input":"2023-09-14T06:22:37.755455Z","iopub.status.idle":"2023-09-14T06:22:37.805876Z","shell.execute_reply.started":"2023-09-14T06:22:37.755422Z","shell.execute_reply":"2023-09-14T06:22:37.804333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to create CSV file or add dataset to the existed CSV file\ndef toCSV(filecsv, class_type,\n          wristX, wristY, wristZ,\n          thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n          thumb_McpX, thumb_McpY, thumb_McpZ,\n          thumb_IpX, thumb_IpY, thumb_IpZ,\n          thumb_TipX, thumb_TipY, thumb_TipZ,\n          index_McpX, index_McpY, index_McpZ,\n          index_PipX, index_PipY, index_PipZ,\n          index_DipX, index_DipY, index_DipZ,\n          index_TipX, index_TipY, index_TipZ,\n          middle_McpX, middle_McpY, middle_McpZ,\n          middle_PipX, middle_PipY, middle_PipZ,\n          middle_DipX, middle_DipY, middle_DipZ,\n          middle_TipX, middle_TipY, middle_TipZ,\n          ring_McpX, ring_McpY, ring_McpZ,\n          ring_PipX, ring_PipY, ring_PipZ,\n          ring_DipX, ring_DipY, ring_DipZ,\n          ring_TipX, ring_TipY, ring_TipZ,\n          pinky_McpX, pinky_McpY, pinky_McpZ,\n          pinky_PipX, pinky_PipY, pinky_PipZ,\n          pinky_DipX, pinky_DipY, pinky_DipZ,\n          pinky_TipX, pinky_TipY, pinky_TipZ):\n    if os.path.isfile(filecsv):\n        #print (\"File exist thus shall write append to the file\")\n        with open(filecsv, 'a+', newline='') as file:\n            # Create a writer object from csv module\n            writer = csv.writer(file)\n            writer.writerow([class_type,\n                             wristX, wristY, wristZ,\n                             thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n                             thumb_McpX, thumb_McpY, thumb_McpZ,\n                             thumb_IpX, thumb_IpY, thumb_IpZ,\n                             thumb_TipX, thumb_TipY, thumb_TipZ,\n                             index_McpX, index_McpY, index_McpZ,\n                             index_PipX, index_PipY, index_PipZ,\n                             index_DipX, index_DipY, index_DipZ,\n                             index_TipX, index_TipY, index_TipZ,\n                             middle_McpX, middle_McpY, middle_McpZ,\n                             middle_PipX, middle_PipY, middle_PipZ,\n                             middle_DipX, middle_DipY, middle_DipZ,\n                             middle_TipX, middle_TipY, middle_TipZ,\n                             ring_McpX, ring_McpY, ring_McpZ,\n                             ring_PipX, ring_PipY, ring_PipZ,\n                             ring_DipX, ring_DipY, ring_DipZ,\n                             ring_TipX, ring_TipY, ring_TipZ,\n                             pinky_McpX, pinky_McpY, pinky_McpZ,\n                             pinky_PipX, pinky_PipY, pinky_PipZ,\n                             pinky_DipX, pinky_DipY, pinky_DipZ,\n                             pinky_TipX, pinky_TipY, pinky_TipZ])\n    else:\n        #print (\"File not exist thus shall create new file as\", filecsv)\n        with open(filecsv, 'w', newline='') as file:\n            # Create a writer object from csv module\n            writer = csv.writer(file)\n            writer.writerow([\"class_type\",\n                             \"wristX\", \"wristY\", \"wristZ\",\n                             \"thumb_CmcX\", \"thumb_CmcY\", \"thumb_CmcZ\",\n                             \"thumb_McpX\", \"thumb_McpY\", \"thumb_McpZ\",\n                             \"thumb_IpX\", \"thumb_IpY\", \"thumb_IpZ\",\n                             \"thumb_TipX\", \"thumb_TipY\", \"thumb_TipZ\",\n                             \"index_McpX\", \"index_McpY\", \"index_McpZ\",\n                             \"index_PipX\", \"index_PipY\", \"index_PipZ\",\n                             \"index_DipX\", \"index_DipY\", \"index_DipZ\",\n                             \"index_TipX\", \"index_TipY\", \"index_TipZ\",\n                             \"middle_McpX\", \"middle_McpY\", \"middle_McpZ\",\n                             \"middle_PipX\", \"middle_PipY\", \"middle_PipZ\",\n                             \"middle_DipX\", \"middle_DipY\", \"middle_DipZ\",\n                             \"middle_TipX\", \"middle_TipY\", \"middle_TipZ\",\n                             \"ring_McpX\", \"ring_McpY\", \"ring_McpZ\",\n                             \"ring_PipX\", \"ring_PipY\", \"ring_PipZ\",\n                             \"ring_DipX\", \"ring_DipY\", \"ring_DipZ\",\n                             \"ring_TipX\", \"ring_TipY\", \"ring_TipZ\",\n                             \"pinky_McpX\", \"pinky_McpY\", \"pinky_McpZ\",\n                             \"pinky_PipX\", \"pinky_PipY\", \"pinky_PipZ\",\n                             \"pinky_DipX\", \"pinky_DipY\", \"pinky_DipZ\",\n                             \"pinky_TipX\", \"pinky_TipY\", \"pinky_TipZ\"])\n            writer.writerow([class_type,\n                             wristX, wristY, wristZ,\n                             thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n                             thumb_McpX, thumb_McpY, thumb_McpZ,\n                             thumb_IpX, thumb_IpY, thumb_IpZ,\n                             thumb_TipX, thumb_TipY, thumb_TipZ,\n                             index_McpX, index_McpY, index_McpZ,\n                             index_PipX, index_PipY, index_PipZ,\n                             index_DipX, index_DipY, index_DipZ,\n                             index_TipX, index_TipY, index_TipZ,\n                             middle_McpX, middle_McpY, middle_McpZ,\n                             middle_PipX, middle_PipY, middle_PipZ,\n                             middle_DipX, middle_DipY, middle_DipZ,\n                             middle_TipX, middle_TipY, middle_TipZ,\n                             ring_McpX, ring_McpY, ring_McpZ,\n                             ring_PipX, ring_PipY, ring_PipZ,\n                             ring_DipX, ring_DipY, ring_DipZ,\n                             ring_TipX, ring_TipY, ring_TipZ,\n                             pinky_McpX, pinky_McpY, pinky_McpZ,\n                             pinky_PipX, pinky_PipY, pinky_PipZ,\n                             pinky_DipX, pinky_DipY, pinky_DipZ,\n                             pinky_TipX, pinky_TipY, pinky_TipZ])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:22:37.897230Z","iopub.execute_input":"2023-09-14T06:22:37.897729Z","iopub.status.idle":"2023-09-14T06:22:37.921239Z","shell.execute_reply.started":"2023-09-14T06:22:37.897691Z","shell.execute_reply":"2023-09-14T06:22:37.919947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract Feature for Training\n# We will using SIBI datasets version V02\npaths = \"/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/\"\ncsv_path = \"hands_SIBI_training.csv\"\n\nif os.path.exists(csv_path):\n    print(\"CSV File does exist, going delete before start extraction and replace it with new\")\n    os.remove(csv_path)\nelse:\n    print(\"The CSV file does not exist\", csv_path, \",Going Create after Extraction\")\n    \nfor dirlist in os.listdir(paths):\n    for root, directories, filenames in os.walk(os.path.join(paths, dirlist)):\n        print(\"Inside Folder\", dirlist, \"Consist :\", len(filenames), \"Imageset\")\n        for filename in filenames:\n            if filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n                #print(os.path.join(root, filename), True)\n                (wristX, wristY, wristZ,\n                 thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n                 thumb_McpX, thumb_McpY, thumb_McpZ,\n                 thumb_IpX, thumb_IpY, thumb_IpZ,\n                 thumb_TipX, thumb_TipY, thumb_TipZ,\n                 index_McpX, index_McpY, index_McpZ,\n                 index_PipX, index_PipY, index_PipZ,\n                 index_DipX, index_DipY, index_DipZ,\n                 index_TipX, index_TipY, index_TipZ,\n                 middle_McpX, middle_McpY, middle_McpZ,\n                 middle_PipX, middle_PipY, middle_PipZ,\n                 middle_DipX, middle_DipY, middle_DipZ,\n                 middle_TipX, middle_TipY, middle_TipZ,\n                 ring_McpX, ring_McpY, ring_McpZ,\n                 ring_PipX, ring_PipY, ring_PipZ,\n                 ring_DipX, ring_DipY, ring_DipZ,\n                 ring_TipX, ring_TipY, ring_TipZ,\n                 pinky_McpX, pinky_McpY, pinky_McpZ,\n                 pinky_PipX, pinky_PipY, pinky_PipZ,\n                 pinky_DipX, pinky_DipY, pinky_DipZ,\n                 pinky_TipX, pinky_TipY, pinky_TipZ,\n                 annotated_image) = extract_feature(os.path.join(root, filename))\n            \n                if ((not wristX == 0) and (not wristY == 0)):\n                    toCSV(csv_path, dirlist, \n                          wristX, wristY, wristZ,\n                          thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n                          thumb_McpX, thumb_McpY, thumb_McpZ,\n                          thumb_IpX, thumb_IpY, thumb_IpZ,\n                          thumb_TipX, thumb_TipY, thumb_TipZ,\n                          index_McpX, index_McpY, index_McpZ,\n                          index_PipX, index_PipY, index_PipZ,\n                          index_DipX, index_DipY, index_DipZ,\n                          index_TipX, index_TipY, index_TipZ,\n                          middle_McpX, middle_McpY, middle_McpZ,\n                          middle_PipX, middle_PipY, middle_PipZ,\n                          middle_DipX, middle_DipY, middle_DipZ,\n                          middle_TipX, middle_TipY, middle_TipZ,\n                          ring_McpX, ring_McpY, ring_McpZ,\n                          ring_PipX, ring_PipY, ring_PipZ,\n                          ring_DipX, ring_DipY, ring_DipZ,\n                          ring_TipX, ring_TipY, ring_TipZ,\n                          pinky_McpX, pinky_McpY, pinky_McpZ,\n                          pinky_PipX, pinky_PipY, pinky_PipZ,\n                          pinky_DipX, pinky_DipY, pinky_DipZ,\n                          pinky_TipX, pinky_TipY, pinky_TipZ,)\n                \n                else :\n                    print(os.path.join(root, filename), \"Hand does not have landmarks\")\n\nprint(\"===================Feature Extraction for TRAINING is Completed===================\")\n                ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:22:38.586996Z","iopub.execute_input":"2023-09-14T06:22:38.587452Z","iopub.status.idle":"2023-09-14T08:48:12.025684Z","shell.execute_reply.started":"2023-09-14T06:22:38.587417Z","shell.execute_reply":"2023-09-14T08:48:12.024716Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Extract Feature for Validation\n# # We will using SIBI datasets version V02\n# paths = \"/kaggle/input/datasets-lemlitbang-sibi-alphabets/SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/validation/\"\n# csv_path = \"hands_SIBI_validation.csv\"\n\n# if os.path.exists(csv_path):\n#     print(\"CSV File does exist, going delete before start extraction and replace it with new\")\n#     os.remove(csv_path)\n# else:\n#     print(\"The CSV file does not exist\", csv_path, \",Going Create after Extraction\")\n    \n# for dirlist in os.listdir(paths):\n#     for root, directories, filenames in os.walk(os.path.join(paths, dirlist)):\n#         print(\"Inside Folder\", dirlist, \"Consist :\", len(filenames), \"Imageset\")\n#         for filename in filenames:\n#             if filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n#                 #print(os.path.join(root, filename), True)\n#                 (wristX, wristY, wristZ,\n#                  thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n#                  thumb_McpX, thumb_McpY, thumb_McpZ,\n#                  thumb_IpX, thumb_IpY, thumb_IpZ,\n#                  thumb_TipX, thumb_TipY, thumb_TipZ,\n#                  index_McpX, index_McpY, index_McpZ,\n#                  index_PipX, index_PipY, index_PipZ,\n#                  index_DipX, index_DipY, index_DipZ,\n#                  index_TipX, index_TipY, index_TipZ,\n#                  middle_McpX, middle_McpY, middle_McpZ,\n#                  middle_PipX, middle_PipY, middle_PipZ,\n#                  middle_DipX, middle_DipY, middle_DipZ,\n#                  middle_TipX, middle_TipY, middle_TipZ,\n#                  ring_McpX, ring_McpY, ring_McpZ,\n#                  ring_PipX, ring_PipY, ring_PipZ,\n#                  ring_DipX, ring_DipY, ring_DipZ,\n#                  ring_TipX, ring_TipY, ring_TipZ,\n#                  pinky_McpX, pinky_McpY, pinky_McpZ,\n#                  pinky_PipX, pinky_PipY, pinky_PipZ,\n#                  pinky_DipX, pinky_DipY, pinky_DipZ,\n#                  pinky_TipX, pinky_TipY, pinky_TipZ,\n#                  annotated_image) = extract_feature(os.path.join(root, filename))\n            \n#                 if ((not wristX == 0) and (not wristY == 0)):\n#                     toCSV(csv_path, dirlist, \n#                           wristX, wristY, wristZ,\n#                           thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n#                           thumb_McpX, thumb_McpY, thumb_McpZ,\n#                           thumb_IpX, thumb_IpY, thumb_IpZ,\n#                           thumb_TipX, thumb_TipY, thumb_TipZ,\n#                           index_McpX, index_McpY, index_McpZ,\n#                           index_PipX, index_PipY, index_PipZ,\n#                           index_DipX, index_DipY, index_DipZ,\n#                           index_TipX, index_TipY, index_TipZ,\n#                           middle_McpX, middle_McpY, middle_McpZ,\n#                           middle_PipX, middle_PipY, middle_PipZ,\n#                           middle_DipX, middle_DipY, middle_DipZ,\n#                           middle_TipX, middle_TipY, middle_TipZ,\n#                           ring_McpX, ring_McpY, ring_McpZ,\n#                           ring_PipX, ring_PipY, ring_PipZ,\n#                           ring_DipX, ring_DipY, ring_DipZ,\n#                           ring_TipX, ring_TipY, ring_TipZ,\n#                           pinky_McpX, pinky_McpY, pinky_McpZ,\n#                           pinky_PipX, pinky_PipY, pinky_PipZ,\n#                           pinky_DipX, pinky_DipY, pinky_DipZ,\n#                           pinky_TipX, pinky_TipY, pinky_TipZ,)\n                \n#                 else :\n#                     print(os.path.join(root, filename), \"Hand does not have landmarks\")\n                \n# print(\"===================Feature Extraction for VALIDATION is Completed===================\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:37:03.617731Z","iopub.execute_input":"2021-08-24T14:37:03.618052Z","iopub.status.idle":"2021-08-24T14:37:37.089819Z","shell.execute_reply.started":"2021-08-24T14:37:03.618017Z","shell.execute_reply":"2021-08-24T14:37:37.087703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read CSV file for Training the model using Pandas\ndf_train = pd.read_csv(\"hands_SIBI_training.csv\", header=0)\n\n# First we must sort the values of the dataset according to the Alphabets\ndf_train = df_train.sort_values(by=[\"class_type\"])\n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T08:49:54.249809Z","iopub.execute_input":"2023-09-14T08:49:54.250211Z","iopub.status.idle":"2023-09-14T08:49:55.883398Z","shell.execute_reply.started":"2023-09-14T08:49:54.250178Z","shell.execute_reply":"2023-09-14T08:49:55.881865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Read CSV file for Validation or Testing the Model using Pandas\n# df_test = pd.read_csv(\"hands_SIBI_validation.csv\", header=0)\n\n# # First we must sort the values of the dataset according to the Alphabets\n# df_test = df_test.sort_values(by=[\"class_type\"])\n\n# df_test","metadata":{"execution":{"iopub.status.busy":"2023-09-14T08:49:56.459992Z","iopub.execute_input":"2023-09-14T08:49:56.460444Z","iopub.status.idle":"2023-09-14T08:49:56.466090Z","shell.execute_reply.started":"2023-09-14T08:49:56.460410Z","shell.execute_reply":"2023-09-14T08:49:56.464682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put Categorical using Pandas\ndf_train[\"class_type\"] = pd.Categorical(df_train[\"class_type\"])\ndf_train[\"class_type\"] = df_train.class_type.cat.codes\n\n# df_test[\"class_type\"] = pd.Categorical(df_test[\"class_type\"])\n# df_test[\"class_type\"] = df_test.class_type.cat.codes","metadata":{"execution":{"iopub.status.busy":"2023-09-14T08:49:56.615219Z","iopub.execute_input":"2023-09-14T08:49:56.615728Z","iopub.status.idle":"2023-09-14T08:49:56.636353Z","shell.execute_reply.started":"2023-09-14T08:49:56.615689Z","shell.execute_reply":"2023-09-14T08:49:56.635085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train.drop('class_type', axis=1)\ny=df_train[\"class_type\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-14T08:49:56.784587Z","iopub.execute_input":"2023-09-14T08:49:56.785307Z","iopub.status.idle":"2023-09-14T08:49:56.808309Z","shell.execute_reply.started":"2023-09-14T08:49:56.785258Z","shell.execute_reply":"2023-09-14T08:49:56.806962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming X is your data and y are your labels\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T08:49:56.970387Z","iopub.execute_input":"2023-09-14T08:49:56.970889Z","iopub.status.idle":"2023-09-14T08:49:57.031908Z","shell.execute_reply.started":"2023-09-14T08:49:56.970853Z","shell.execute_reply":"2023-09-14T08:49:57.030676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx_train = np.array(x_train)\nx_test = np.array(x_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T08:49:57.876348Z","iopub.execute_input":"2023-09-14T08:49:57.876839Z","iopub.status.idle":"2023-09-14T08:49:57.907097Z","shell.execute_reply.started":"2023-09-14T08:49:57.876802Z","shell.execute_reply":"2023-09-14T08:49:57.905844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Array Shape before transformation\nprint(x_train.shape)\nprint(x_test.shape)\n\n# Since the array shape is 1x1, we must turn it into 1x10x1 so we can feed it into the model\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n\n# Check Array Shape after transformation\nprint(x_train.shape)\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T08:49:58.073960Z","iopub.execute_input":"2023-09-14T08:49:58.074807Z","iopub.status.idle":"2023-09-14T08:49:58.084608Z","shell.execute_reply.started":"2023-09-14T08:49:58.074761Z","shell.execute_reply":"2023-09-14T08:49:58.083061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check sample train and test features\nprint(x_train[0])\nprint(x_test[7])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T08:49:58.989278Z","iopub.execute_input":"2023-09-14T08:49:58.989727Z","iopub.status.idle":"2023-09-14T08:49:58.999479Z","shell.execute_reply.started":"2023-09-14T08:49:58.989696Z","shell.execute_reply":"2023-09-14T08:49:58.997525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of classes according standard Indonesian Language Alphabets\nnum_classes = 29\n\n# Using the Keras.Utils to put the label categorically \ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T08:50:02.053189Z","iopub.execute_input":"2023-09-14T08:50:02.053942Z","iopub.status.idle":"2023-09-14T08:50:02.063817Z","shell.execute_reply.started":"2023-09-14T08:50:02.053906Z","shell.execute_reply":"2023-09-14T08:50:02.062890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# Name of the model\nmodel_name = \"best_model.h5\"\n\n# ModelCheckpoint callback\ncheckpoint = ModelCheckpoint(model_name,\n                             monitor=\"val_loss\",\n                             mode=\"min\",\n                             save_best_only=True,\n                             verbose=1)\n\n# EarlyStopping callback\nearlystopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,  # Reduced patience to 3\n                              verbose=1,\n                              restore_best_weights=True)\n\n# ReduceLROnPlateau callback\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n                                            patience=2,  # Reduced patience to 2\n                                            verbose=1,\n                                            factor=0.5,  # Changed factor to 0.5\n                                            min_lr=0.00001)  # Added minimum learning rate","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:25:42.870900Z","iopub.execute_input":"2023-09-14T09:25:42.871399Z","iopub.status.idle":"2023-09-14T09:25:42.879884Z","shell.execute_reply.started":"2023-09-14T09:25:42.871363Z","shell.execute_reply":"2023-09-14T09:25:42.878664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import regularizers\nfrom tensorflow.keras.optimizers import Adam\n\n# Defining the model\nmodel = tf.keras.models.Sequential([\n    # First Convolutional layer with 32 filters\n    tf.keras.layers.Conv1D(filters=32, kernel_size=3, strides=1, padding=\"causal\", activation=\"relu\", input_shape=x_train.shape[1:3]),\n    \n    # Max Pooling layer with pool size of 2\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    \n    # Second Convolutional layer with 64 filters\n    tf.keras.layers.Conv1D(filters=64, kernel_size=3, strides=1, padding=\"causal\", activation=\"relu\"),\n    \n    # Max Pooling layer\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    \n    # Third Convolutional layer with 128 filters\n    tf.keras.layers.Conv1D(filters=128, kernel_size=3, strides=1, padding=\"causal\", activation=\"relu\"),\n    \n    # Max Pooling layer\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    \n    # Dropout layer with dropout rate of 0.5 to prevent overfitting\n    tf.keras.layers.Dropout(rate=0.5),\n    \n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    \n    # Dense hidden layer with 256 neurons and 'relu' activation function\n    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  # Added L2 regularization\n    \n    # Output layer with 'num_classes' neurons (one for each class) and 'softmax' activation function for multi-class classification\n    tf.keras.layers.Dense(num_classes, activation='softmax')])\n\n\n# Reduced learning rate\noptimizer = Adam(learning_rate=0.001)\n\n# Compiling the model with 'categorical_crossentropy' loss function (for multi-class classification), 'adam' optimizer and accuracy as the metric\nmodel.compile(loss = 'categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n# Training the model with early stopping callback\n\n# Printing the summary of the model\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:25:43.085854Z","iopub.execute_input":"2023-09-14T09:25:43.086565Z","iopub.status.idle":"2023-09-14T09:25:43.257875Z","shell.execute_reply.started":"2023-09-14T09:25:43.086529Z","shell.execute_reply":"2023-09-14T09:25:43.256396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train the Model\nhistory=model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test),callbacks=[checkpoint,earlystopping,learning_rate_reduction])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:02:16.972591Z","iopub.execute_input":"2023-09-14T09:02:16.973075Z","iopub.status.idle":"2023-09-14T09:21:52.048204Z","shell.execute_reply.started":"2023-09-14T09:02:16.973038Z","shell.execute_reply":"2023-09-14T09:21:52.046621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # One Dimensional Convolutional Neural Network model, Train will be feed to 1 Dimension Convolutional Neural Network\n# model = tf.keras.models.Sequential([\n#     tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\", input_shape=x_train.shape[1:3]),\n#     tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.MaxPooling1D(pool_size=2),\n#     tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.MaxPooling1D(pool_size=2),\n#     tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.MaxPooling1D(pool_size=2),\n#     tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n#     tf.keras.layers.MaxPooling1D(pool_size=2),\n#     tf.keras.layers.Dropout(rate=0.2),\n#     # Flatten the results to feed into a DNN\n#     tf.keras.layers.Flatten(),\n#     # 512 neuron hidden layer\n#     tf.keras.layers.Dense(512, activation='relu'), \n#     tf.keras.layers.Dense(num_classes, activation='softmax')])\n\n# model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:26:25.523774Z","iopub.execute_input":"2023-09-13T18:26:25.524856Z","iopub.status.idle":"2023-09-13T18:26:25.741741Z","shell.execute_reply.started":"2023-09-13T18:26:25.524816Z","shell.execute_reply":"2023-09-13T18:26:25.740832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:23:38.763108Z","iopub.execute_input":"2023-09-14T09:23:38.763615Z","iopub.status.idle":"2023-09-14T09:23:39.183295Z","shell.execute_reply.started":"2023-09-14T09:23:38.763563Z","shell.execute_reply":"2023-09-14T09:23:39.181788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:23:40.202250Z","iopub.execute_input":"2023-09-14T09:23:40.202745Z","iopub.status.idle":"2023-09-14T09:23:40.621082Z","shell.execute_reply.started":"2023-09-14T09:23:40.202707Z","shell.execute_reply":"2023-09-14T09:23:40.619725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving the model into H5 system file\nsave_model = \"model_en.h5\"\nmodel.save(save_model)\nprint(\"Model Saved into\", save_model)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:23:41.624138Z","iopub.execute_input":"2023-09-14T09:23:41.624580Z","iopub.status.idle":"2023-09-14T09:23:41.669587Z","shell.execute_reply.started":"2023-09-14T09:23:41.624547Z","shell.execute_reply":"2023-09-14T09:23:41.668691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = np.argmax(y_test,axis=1)\ny_pred = model.predict(x_test)\ny_pred = np.argmax(y_pred,axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:23:43.066187Z","iopub.execute_input":"2023-09-14T09:23:43.067643Z","iopub.status.idle":"2023-09-14T09:23:45.851366Z","shell.execute_reply.started":"2023-09-14T09:23:43.067582Z","shell.execute_reply":"2023-09-14T09:23:45.850335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='.3g',cmap='viridis')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:23:45.853704Z","iopub.execute_input":"2023-09-14T09:23:45.855004Z","iopub.status.idle":"2023-09-14T09:23:48.079204Z","shell.execute_reply.started":"2023-09-14T09:23:45.854958Z","shell.execute_reply":"2023-09-14T09:23:48.078136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# Convert the model.\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model_en.tflite', 'wb') as f:\n  f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:24:45.051894Z","iopub.execute_input":"2023-09-14T09:24:45.052372Z","iopub.status.idle":"2023-09-14T09:24:48.260884Z","shell.execute_reply.started":"2023-09-14T09:24:45.052335Z","shell.execute_reply":"2023-09-14T09:24:48.258987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hard Encode for the Prediction\nclasses = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'nothing': 27, 'space': 28}","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:23:53.652797Z","iopub.execute_input":"2023-09-14T09:23:53.653167Z","iopub.status.idle":"2023-09-14T09:23:53.661012Z","shell.execute_reply.started":"2023-09-14T09:23:53.653134Z","shell.execute_reply":"2023-09-14T09:23:53.659390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:23:53.662592Z","iopub.execute_input":"2023-09-14T09:23:53.662979Z","iopub.status.idle":"2023-09-14T09:23:53.676098Z","shell.execute_reply.started":"2023-09-14T09:23:53.662940Z","shell.execute_reply":"2023-09-14T09:23:53.674781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directly from Imageset Dataset Testing\n#Load Image and do Feature Extraction\npath_to_image = \"/kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/I_test.jpg\"\n\n(wristX, wristY, wristZ,\n thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n thumb_McpX, thumb_McpY, thumb_McpZ,\n thumb_IpX, thumb_IpY, thumb_IpZ,\n thumb_TipX, thumb_TipY, thumb_TipZ,\n index_McpX, index_McpY, index_McpZ,\n index_PipX, index_PipY, index_PipZ,\n index_DipX, index_DipY, index_DipZ,\n index_TipX, index_TipY, index_TipZ,\n middle_McpX, middle_McpY, middle_McpZ,\n middle_PipX, middle_PipY, middle_PipZ,\n middle_DipX, middle_DipY, middle_DipZ,\n middle_TipX, middle_TipY, middle_TipZ,\n ring_McpX, ring_McpY, ring_McpZ,\n ring_PipX, ring_PipY, ring_PipZ,\n ring_DipX, ring_DipY, ring_DipZ,\n ring_TipX, ring_TipY, ring_TipZ,\n pinky_McpX, pinky_McpY, pinky_McpZ,\n pinky_PipX, pinky_PipY, pinky_PipZ,\n pinky_DipX, pinky_DipY, pinky_DipZ,\n pinky_TipX, pinky_TipY, pinky_TipZ,\n output_IMG) = extract_feature(path_to_image)\n\n#print(wristX, wristY,\n#      thumb_CmcX, thumb_CmcY, thumb_McpX, thumb_McpY, thumb_IpX, thumb_IpY, thumb_TipX, thumb_TipY,\n#      index_McpX, index_McpY, index_PipX, index_PipY, index_DipX, index_DipY, index_TipX, index_TipY,\n#      middle_McpX, middle_McpY, middle_PipX, middle_PipY, middle_DipX, middle_DipY, middle_TipX, middle_TipY,\n#      ring_McpX, ring_McpY, ring_PipX, ring_PipY, ring_DipX, ring_DipY, ring_TipX, ring_TipY,\n#      pinky_McpX, pinky_McpY, pinky_PipX, pinky_PipY, pinky_DipX, pinky_DipY, pinky_TipX, pinky_TipY)\nplt.axis(\"on\")\nplt.imshow(cv.cvtColor(output_IMG, cv.COLOR_BGR2RGB))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:24:09.194821Z","iopub.execute_input":"2023-09-14T09:24:09.195252Z","iopub.status.idle":"2023-09-14T09:24:09.646064Z","shell.execute_reply.started":"2023-09-14T09:24:09.195220Z","shell.execute_reply":"2023-09-14T09:24:09.644581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Shape the image features into an 1x3 array.\ninput_IMG = np.array([[[wristX], [wristY], [wristZ],\n                     [thumb_CmcX], [thumb_CmcY], [thumb_CmcZ],\n                     [thumb_McpX], [thumb_McpY], [thumb_McpZ],\n                     [thumb_IpX], [thumb_IpY], [thumb_IpZ],\n                     [thumb_TipX], [thumb_TipY], [thumb_TipZ],\n                     [index_McpX], [index_McpY], [index_McpZ],\n                     [index_PipX], [index_PipY], [index_PipZ],\n                     [index_DipX], [index_DipY], [index_DipZ],\n                     [index_TipX], [index_TipY], [index_TipZ],\n                     [middle_McpX], [middle_McpY], [middle_McpZ],\n                     [middle_PipX], [middle_PipY], [middle_PipZ],\n                     [middle_DipX], [middle_DipY], [middle_DipZ],\n                     [middle_TipX], [middle_TipY], [middle_TipZ],\n                     [ring_McpX], [ring_McpY], [ring_McpZ],\n                     [ring_PipX], [ring_PipY], [ring_PipZ],\n                     [ring_DipX], [ring_DipY], [ring_DipZ],\n                     [ring_TipX], [ring_TipY], [ring_TipZ],\n                     [pinky_McpX], [pinky_McpY], [pinky_McpZ],\n                     [pinky_PipX], [pinky_PipY], [pinky_PipZ],\n                     [pinky_DipX], [pinky_DipY], [pinky_DipZ],\n                     [pinky_TipX], [pinky_TipY], [pinky_TipZ]]])\n\nprint(input_IMG.shape)\nprint(input_IMG)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:24:10.982090Z","iopub.execute_input":"2023-09-14T09:24:10.983317Z","iopub.status.idle":"2023-09-14T09:24:10.998048Z","shell.execute_reply.started":"2023-09-14T09:24:10.983252Z","shell.execute_reply":"2023-09-14T09:24:10.996682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the Prediction\nprint(model.predict(input_IMG))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:24:11.195973Z","iopub.execute_input":"2023-09-14T09:24:11.196383Z","iopub.status.idle":"2023-09-14T09:24:11.271282Z","shell.execute_reply.started":"2023-09-14T09:24:11.196353Z","shell.execute_reply":"2023-09-14T09:24:11.270492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print prediction using defined Classes\npredictions = model.predict(input_IMG)\npredictions=np.argmax(predictions,axis=1)\nfor alphabets, values in classes.items():\n    if values == predictions[0] :\n        print(\"Possible Alphabet according to the input : \", alphabets)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:24:11.777371Z","iopub.execute_input":"2023-09-14T09:24:11.777866Z","iopub.status.idle":"2023-09-14T09:24:11.858787Z","shell.execute_reply.started":"2023-09-14T09:24:11.777831Z","shell.execute_reply":"2023-09-14T09:24:11.857673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}